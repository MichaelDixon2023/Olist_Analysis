{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ced72cf",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bcae0",
   "metadata": {},
   "source": [
    "## 1: Overview: \n",
    "\n",
    "I completed the EDA of the financial data of Olist, a Brazilian based e-commerce company. The data was provided via kaggle and contains sales data from 2016-2018. 9 .csv files were provided with information on the products, customers and retailers on the site. After exploring the factors that drive an increase in sales (such as location, quality of product, type of product, etc), I wanted to use my knowledge of predictive modeling to predict revenue. The same SQL database from notebook \"EDA\" is queried here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a213935",
   "metadata": {},
   "source": [
    "## 2: Relevant Code for Preparation: \n",
    "\n",
    "The following code chunk(s) are provided to load the necessary packages for my analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30d0ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages for work\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e93b4f",
   "metadata": {},
   "source": [
    "## 3: Linear Model: \n",
    "\n",
    "Below I create a linear model to serve as a baseline of accuracy. Linear models are very simple, which makes them easy to both implement and understand. However, the tradeoff of using the model is that it often lacks the accuracy and generalizability of other, more advanced models. I implement these more advanced techniques later in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "476df27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to SQL database to get data for modeling\n",
    "connection_to_database = sqlite3.connect(\"Olist_DB.db\")\n",
    "\n",
    "try:\n",
    "    SQL_data = \"\"\"\n",
    "    SELECT *\n",
    "    FROM  olist_customers_dataset\n",
    "    LEFT JOIN olist_orders_dataset\n",
    "    USING(customer_id)\n",
    "    LEFT JOIN olist_order_items_dataset\n",
    "    USING(order_id)\n",
    "    LEFT JOIN olist_order_reviews_dataset\n",
    "    USING(order_id)\n",
    "    LEFT JOIN olist_products_dataset\n",
    "    USING(product_id)\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(SQL_data, connection_to_database)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "finally:\n",
    "    connection_to_database.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66e60b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'customer_city' column\n",
    "df = pd.get_dummies(df, columns=['customer_city'], prefix='city', drop_first=True)\n",
    "\n",
    "#drop NAs and replace with median\n",
    "df['review_score'] = df['review_score'].fillna(df['review_score'].median())\n",
    "df['product_weight_g'] = df['product_weight_g'].fillna(df['product_weight_g'].median())\n",
    "df['price'] = df['price'].fillna(df['price'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf2f1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.0457834021466853e+18\n",
      "R-squared: -31904766228491.55\n"
     ]
    }
   ],
   "source": [
    "X = df[['review_score', 'product_weight_g'] + [col for col in df.columns if col.startswith('city_')]]\n",
    "y = df['price'] \n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 20022121)\n",
    "\n",
    "# Initializing the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Optional: Displaying model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': linear_model.coef_\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b372a5",
   "metadata": {},
   "source": [
    "The very large MSE score as well as a large negative R^2 indiacte this is an extremely weak model to use. It could be due to the simplicity of a linear regression, or it could be due to the variables chosen. We will refine both in the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526d7b3",
   "metadata": {},
   "source": [
    "## 4: Decision Tree: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e458aac",
   "metadata": {},
   "source": [
    "I now create a decision tree with slightly different variables to try to improve the model performance. Decision trees are fairly simple to understand, just like linear regression, but they tend to be more robust. I use the variables of product review, product weight, city. However, I will now determine the number of days between the purchase date of the order and the delivery date to weigh how important expediant delivery is in driving sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aef184a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>...</th>\n",
       "      <th>city_xanxere</th>\n",
       "      <th>city_xapuri</th>\n",
       "      <th>city_xavantina</th>\n",
       "      <th>city_xaxim</th>\n",
       "      <th>city_xexeu</th>\n",
       "      <th>city_xinguara</th>\n",
       "      <th>city_xique-xique</th>\n",
       "      <th>city_zacarias</th>\n",
       "      <th>city_ze doca</th>\n",
       "      <th>city_zortea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>SP</td>\n",
       "      <td>00e7ee1b050b8499577073aeb2a297a1</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-05-16 15:05:35</td>\n",
       "      <td>2017-05-16 15:22:12</td>\n",
       "      <td>2017-05-23 10:47:57</td>\n",
       "      <td>2017-05-25 10:35:35</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>SP</td>\n",
       "      <td>29150127e6685892b6eab3eec79f59c7</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-01-12 20:48:24</td>\n",
       "      <td>2018-01-12 20:58:32</td>\n",
       "      <td>2018-01-15 17:14:59</td>\n",
       "      <td>2018-01-29 12:41:19</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>SP</td>\n",
       "      <td>b2059ed67ce144a36e2aa97d2c9e9ad2</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-05-19 16:07:45</td>\n",
       "      <td>2018-05-20 16:19:10</td>\n",
       "      <td>2018-06-11 14:31:00</td>\n",
       "      <td>2018-06-14 17:58:51</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>SP</td>\n",
       "      <td>951670f92359f4fe4a63112aa7306eba</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-03-13 16:06:38</td>\n",
       "      <td>2018-03-13 17:29:19</td>\n",
       "      <td>2018-03-27 23:22:42</td>\n",
       "      <td>2018-03-28 16:04:25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>SP</td>\n",
       "      <td>6b7d50bd145f6fc7f33cebabd7e49d0f</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-29 09:51:30</td>\n",
       "      <td>2018-07-29 10:10:09</td>\n",
       "      <td>2018-07-30 15:16:00</td>\n",
       "      <td>2018-08-09 20:55:48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix customer_state                          order_id  \\\n",
       "0                     14409             SP  00e7ee1b050b8499577073aeb2a297a1   \n",
       "1                      9790             SP  29150127e6685892b6eab3eec79f59c7   \n",
       "2                      1151             SP  b2059ed67ce144a36e2aa97d2c9e9ad2   \n",
       "3                      8775             SP  951670f92359f4fe4a63112aa7306eba   \n",
       "4                     13056             SP  6b7d50bd145f6fc7f33cebabd7e49d0f   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-05-16 15:05:35  2017-05-16 15:22:12   \n",
       "1    delivered      2018-01-12 20:48:24  2018-01-12 20:58:32   \n",
       "2    delivered      2018-05-19 16:07:45  2018-05-20 16:19:10   \n",
       "3    delivered      2018-03-13 16:06:38  2018-03-13 17:29:19   \n",
       "4    delivered      2018-07-29 09:51:30  2018-07-29 10:10:09   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  ...  \\\n",
       "0          2017-05-23 10:47:57           2017-05-25 10:35:35  ...   \n",
       "1          2018-01-15 17:14:59           2018-01-29 12:41:19  ...   \n",
       "2          2018-06-11 14:31:00           2018-06-14 17:58:51  ...   \n",
       "3          2018-03-27 23:22:42           2018-03-28 16:04:25  ...   \n",
       "4          2018-07-30 15:16:00           2018-08-09 20:55:48  ...   \n",
       "\n",
       "  city_xanxere  city_xapuri city_xavantina city_xaxim city_xexeu  \\\n",
       "0        False        False          False      False      False   \n",
       "1        False        False          False      False      False   \n",
       "2        False        False          False      False      False   \n",
       "3        False        False          False      False      False   \n",
       "4        False        False          False      False      False   \n",
       "\n",
       "   city_xinguara  city_xique-xique city_zacarias  city_ze doca city_zortea  \n",
       "0          False             False         False         False       False  \n",
       "1          False             False         False         False       False  \n",
       "2          False             False         False         False       False  \n",
       "3          False             False         False         False       False  \n",
       "4          False             False         False         False       False  \n",
       "\n",
       "[5 rows x 4149 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66581faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to date time for calculations\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "\n",
    "#calculate difference between order date and delivery date\n",
    "df['day_difference'] = (df['order_delivered_customer_date'] - df['order_approved_at']).dt.days\n",
    "\n",
    "#replace missing NAs with median\n",
    "df['day_difference'] = df['day_difference'].fillna(df['day_difference'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b31d2111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 44708.80\n",
      "Mean Absolute Error (MAE): 79.77\n",
      "R-squared (R²): -0.3640\n"
     ]
    }
   ],
   "source": [
    "X = df[['review_score', 'product_weight_g', 'day_difference'] + [col for col in df.columns if col.startswith('city_')]]\n",
    "y = df['price'] \n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 20022121)\n",
    "\n",
    "#create model\n",
    "tree_model = DecisionTreeRegressor(random_state=20022121)\n",
    "\n",
    "# Fit the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6930b3",
   "metadata": {},
   "source": [
    "While a negative R^2 still implies a weak model, and an absolute error of almost 80 when the mean price is 120 is pretty weak as well, it is important to note the huge improvements using a decision tree has given me. The R^2 is magnitudes lower than it was previoulsy and so is the MSE score. Futher tweaking of the model could lead to even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f27bc",
   "metadata": {},
   "source": [
    "## 4: XGBoost: \n",
    "\n",
    "XGBoost has become quite popular in the world of machine learning because it takes the strong results of a tree based model like above but builds the trees in parallel from \"boosting\", where each new tree learns from the previous one. This is also different than random forest models which build the trees independent of each other then weigh the results. Another advantage tree based modeling has over more advanced neural networks is they do not require as much data to be trained on. Our dataset has over ten thousand entries, which is a lot, but not enough to adequately train a deep learning network. The modeling is conducted below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99c67436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 28496.30\n",
      "Mean Absolute Error (MAE): 78.14\n",
      "R-squared (R²): 0.1306\n"
     ]
    }
   ],
   "source": [
    "#set variables\n",
    "X = df[['review_score', 'product_weight_g', 'day_difference'] + [col for col in df.columns if col.startswith('city_')]]\n",
    "y = df['price'] \n",
    "\n",
    "#split training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 20022121)\n",
    "\n",
    "#create model\n",
    "XGB_model = XGBRegressor(random_state=20022121)\n",
    "\n",
    "# Fit the model\n",
    "XGB_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = XGB_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46c64f",
   "metadata": {},
   "source": [
    "### 5: Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15ad95",
   "metadata": {},
   "source": [
    "The final model, XGBoost, produced by far the best results. With the lowest MSE and MAE, it out peformed the previous two models. However, the best results have come in the form of the R^2 metric. Initially a massive negative number in the linear model, we now have a small positive value, 0.1306, as a reflection of our accuracy. Again, while this value indicates our model is far from perfect, it shows two key elements. First, that XGBoost modeling is more robust than our other two tested in this analysis. Second, it shows that the features tested (weight of product, review scores, delivery times and city) could all be huge factors in driving sales. \n",
    "\n",
    "\n",
    "For a future analysis, I would want to focus on a few more key cities, as I think the vast number of cities we had to one hot encode essentially bogs down the model and leads to overfitting. Given more time, I would also like to test a few more modeling techniques to compare them to the succes of the XGBoost. Finally, our dataset had a massive number of features, and given more time, I would like to test even more of them in the feature selection process of my analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
